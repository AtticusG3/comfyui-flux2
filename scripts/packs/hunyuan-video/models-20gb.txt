# Hunyuan Video (20GB / LOW_VRAM=false)
# Tutorial: https://docs.comfy.org/tutorials/video/hunyuan/hunyuan-video
# Full T2V and I2V workflows. Use --highvram for best performance.

# Text encoder: CLIP-L (shared)
https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/text_encoders/clip_l.safetensors
  dir=ComfyUI/models/text_encoders
  out=clip_l.safetensors

# Text encoder: LLaVA LLaMA3 (FP8 scaled)
https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/text_encoders/llava_llama3_fp8_scaled.safetensors
  dir=ComfyUI/models/text_encoders
  out=llava_llama3_fp8_scaled.safetensors

# VAE
https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/vae/hunyuan_video_vae_bf16.safetensors
  dir=ComfyUI/models/vae
  out=hunyuan_video_vae_bf16.safetensors

# Diffusion model: Text-to-Video 720p
https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/diffusion_models/hunyuan_video_t2v_720p_bf16.safetensors
  dir=ComfyUI/models/diffusion_models
  out=hunyuan_video_t2v_720p_bf16.safetensors

# CLIP Vision (for I2V)
https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/clip_vision/llava_llama3_vision.safetensors
  dir=ComfyUI/models/clip_vision
  out=llava_llama3_vision.safetensors

# Diffusion model: Image-to-Video 720p (v1 "concat")
https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/diffusion_models/hunyuan_video_image_to_video_720p_bf16.safetensors
  dir=ComfyUI/models/diffusion_models
  out=hunyuan_video_image_to_video_720p_bf16.safetensors
